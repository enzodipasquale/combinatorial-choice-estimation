{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:  True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "import itertools\n",
    "from itertools import product\n",
    "import torch\n",
    "\n",
    "print('mps: ', torch.backends.mps.is_available())\n",
    "\n",
    "options = {\n",
    " \"WLSACCESSID\":\"a4353fb7-f95b-4075-b288-ca3f60983b36\",\n",
    "\"WLSSECRET\":\"d894d460-2dac-4210-8c40-c91c68ecfb13\",\n",
    "\"LICENSEID\":2562382\n",
    "}\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use the Metal backend\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BundledChoiceKP:\n",
    "    def __init__(self,  num_agents , num_objects , lambda_star = None, num_simulations = 20, \n",
    "                 random_seed = 4,  sigma = 1, max_capacity = 100, generate_data = True):\n",
    "\n",
    "        self.num_agents = num_agents\n",
    "        self.num_objects = num_objects\n",
    "        self.num_simulations = num_simulations\n",
    "\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "        self.device = device\n",
    "        self.agents_si = torch.kron(torch.ones(self.num_simulations, dtype = torch.int), torch.arange(self.num_agents))\n",
    "\n",
    "        \n",
    "        if lambda_star is not None:           \n",
    "            # True parameters\n",
    "            self.K_MOD = len(lambda_star)\n",
    "            self.lambda_star_np = lambda_star\n",
    "            self.lambda_star = torch.tensor(lambda_star, device=device, dtype=torch.float)\n",
    "\n",
    "        else:                                 \n",
    "            self.K_MOD = None\n",
    "            self.lambda_star_np = None\n",
    "            self.lambda_star = None\n",
    "\n",
    "        if generate_data is True:\n",
    "            # Set manual seed\n",
    "            torch.manual_seed(self.random_seed)\n",
    "\n",
    "            ### Modular characteristics\n",
    "            self.φ_i_j_k = torch.normal(0, 1, size=(self.num_agents, self.num_objects, self.K_MOD), \n",
    "                                        device=device, dtype=torch.float)\n",
    "\n",
    "            ### Knapsack Constraints\n",
    "            self.weight_j = torch.randint(1, 100, (self.num_objects,), device=device, dtype = torch.int)\n",
    "            self.capacity_i = torch.randint(1, max_capacity, (self.num_agents,), device=device, dtype=torch.int) \n",
    "        else:\n",
    "            self.φ_i_j_k = None\n",
    "            self.weight_j = None\n",
    "            self.capacity_i = None\n",
    "        \n",
    "    \n",
    "        ### Estimation\n",
    "        self.φ_hat_k = None\n",
    "        self.φ_hat_i_k = None\n",
    "        self.value_LP = None\n",
    "\n",
    "        self.eps_i_j = sigma * torch.normal(0, 1, size=(self.num_agents, self.num_objects), device=device, dtype=torch.float)\n",
    "        self.eps_si_j = sigma * torch.normal(0, 1, size=(self.num_simulations * self.num_agents, self.num_objects), \n",
    "                                             device=device, dtype=torch.float)\n",
    "\n",
    "    def load_data(self, characteristic_i_j, weight_j, capacity_i, matching_i_j):\n",
    "        # set the characteristic function (torch tensor)\n",
    "        self.φ_i_j_k  = torch.tensor(characteristic_i_j, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # set the weight of the objects (torch tensor int64)\n",
    "        self.weight_j = torch.tensor(weight_j, dtype=torch.int64, device=self.device)\n",
    "        self.capacity_i = torch.tensor(capacity_i, dtype=torch.int64, device=self.device)\n",
    "        matching_i_j = torch.tensor(matching_i_j, dtype=torch.bool, device=self.device)\n",
    "        self.φ_hat_k = (self.φ_i_j_k * matching_i_j.unsqueeze(2)).sum((0,1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_knapsack(self, idx, lambda_k , max_weight = None, p_j = None, eps_i_j = None, return_value = False):\n",
    "    \n",
    "    ### Compute the values\n",
    "    profit_i_j = self.φ_i_j_k[idx]  @  lambda_k \n",
    "\n",
    "    if p_j is not None:\n",
    "        profit_i_j -= p_j.unsqueeze(0)\n",
    "    if eps_i_j is not None:\n",
    "        profit_i_j += eps_i_j\n",
    "\n",
    "    if max_weight is None:\n",
    "        max_weight = int(self.capacity_i[idx].max())\n",
    "    \n",
    "    ### Fill in the DP table\n",
    "    value_i_j_w = torch.zeros((len(idx), self.num_objects +1, max_weight +1) ,device=device, dtype=torch.float)\n",
    "    weight_states = torch.arange(max_weight + 1, device = device)\n",
    "\n",
    "    # print type of weight_states\n",
    "    for j in range(self.num_objects):\n",
    "        value_i_j_w[:, j+1, :] = torch.where(self.weight_j[j] <= weight_states, \n",
    "                                    torch.maximum(profit_i_j[:, j].unsqueeze(1) + value_i_j_w[:, j, weight_states - self.weight_j[j]],\n",
    "                                                value_i_j_w[:, j, :]), \n",
    "                                        value_i_j_w[:, j, :])\n",
    "\n",
    "    ### Backtrack to find the items\n",
    "    residual_weight = self.capacity_i[idx]\n",
    "    B_i_j_star = torch.zeros((len(idx), self.num_objects), device=device, dtype= bool)\n",
    "\n",
    "    for j in range(self.num_objects,0,-1):\n",
    "\n",
    "        pick_j = (value_i_j_w[torch.arange(len(idx)), j, residual_weight] > \n",
    "                    value_i_j_w[torch.arange(len(idx)), j-1, residual_weight])\n",
    "        \n",
    "        B_i_j_star[:, j-1] = pick_j\n",
    "        residual_weight -= pick_j * self.weight_j[j-1]\n",
    "\n",
    "    if return_value:\n",
    "        return B_i_j_star, value_i_j_w[torch.arange(len(idx)), -1 , self.capacity_i[idx]]\n",
    "    else:\n",
    "        return B_i_j_star \n",
    "\n",
    "BundledChoiceKP.linear_knapsack = linear_knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_bundle_choice(self, add_noise = False):\n",
    "\n",
    "    noise = self.eps_i_j if add_noise else None\n",
    "\n",
    "    B_i_j_star = self.linear_knapsack(torch.arange(self.num_agents), self.lambda_star, eps_i_j = noise)\n",
    "\n",
    "    self.φ_hat_i_k = (self.φ_i_j_k * B_i_j_star.unsqueeze(2)).sum(1)\n",
    "    self.φ_hat_k = self.φ_hat_i_k.sum(0)\n",
    "\n",
    "    print(\"# characteristics: \",self.K_MOD)\n",
    "    print(\"φ_hat_k: \", self.φ_hat_k.cpu().numpy())\n",
    "\n",
    "BundledChoiceKP.generate_data_bundle_choice = generate_data_bundle_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_minmaxregret_BChoice(self, max_iters = 100 ,tol = 1e-2 ):\n",
    "      with gp.Env(params=options) as env:\n",
    "          with gp.Model(env=env) as model:\n",
    "              ### Initialize\n",
    "              # Create variables\n",
    "              lambda_k = model.addVars(self.K_MOD - 1, lb= 0, ub = 1e8 , name=\"parameters\")\n",
    "              u_i = model.addVars(self.num_agents, lb = 0, ub = 1e8 , name=\"utilities\")\n",
    "\n",
    "              # Set objective and initial constraints\n",
    "              model.setObjective(gp.quicksum( self.φ_hat_k[k+1] * lambda_k[k] for k in range(self.K_MOD - 1))\n",
    "                                  - u_i.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "              model.addConstrs(\n",
    "                            (u_i[i] >= gp.quicksum((self.φ_hat_i_k[i, k+1]) * lambda_k[k]  for k in range(self.K_MOD - 1))\n",
    "                            + self.φ_hat_i_k[i, 0]\n",
    "                            for i in range(self.num_agents))\n",
    "                              )\n",
    "              \n",
    "              # Solve master problem \n",
    "              model.setParam('OutputFlag', 0)\n",
    "              model.optimize()\n",
    "              theta_solution = np.array(model.x)\n",
    "\n",
    "              iter = 0\n",
    "              while iter < max_iters:\n",
    "                  print('################')\n",
    "                  print(f\"ITER: {iter}, parameters: {theta_solution[:self.K_MOD-1].round(3)}\")\n",
    "\n",
    "                  ### Pricing problem\n",
    "                  lambda_k_iter = torch.cat((torch.tensor([1.0], device= device),\n",
    "                                               torch.tensor(theta_solution[:self.K_MOD-1], device= device , dtype=torch.float32)))\n",
    "\n",
    "\n",
    "                  B_star_i = self.linear_knapsack(torch.arange(self.num_agents), lambda_k_iter)\n",
    "\n",
    "                  val_i =  (self.φ_i_j_k * B_star_i.unsqueeze(2)).sum(1) @ lambda_k_iter\n",
    "\n",
    "                  ### Stop if certificate holds\n",
    "                  certificate_i = val_i.cpu().numpy() - theta_solution[self.K_MOD-1:]\n",
    "                  max_certificate = np.max(certificate_i)\n",
    "\n",
    "                  print(\"Value of LP:   \", model.objVal)\n",
    "                  print(f\"Reduced cost: {max_certificate}\")\n",
    "\n",
    "                  if max_certificate < tol:\n",
    "                    primal_solution = np.array(model.x)\n",
    "                    dual_solution = np.array(model.pi)\n",
    "                    print('#############################################')\n",
    "                    print('#############################################')\n",
    "                    print(\"Solution:       \", primal_solution[:self.K_MOD-1].round(3))\n",
    "                    print(\"True parameters:\", self.lambda_star_np[1:])\n",
    "                    print('###############')\n",
    "                    return primal_solution\n",
    "\n",
    "                    \n",
    "\n",
    "                  ### Master problem\n",
    "                  # Add constraints\n",
    "\n",
    "                  φ_i_k_star = (self.φ_i_j_k * B_star_i.unsqueeze(2)).sum(1)\n",
    "\n",
    "                  model.addConstrs(\n",
    "                            (u_i[i] >= gp.quicksum((φ_i_k_star[i, k+1]) * lambda_k[k]  for k in range(self.K_MOD - 1))\n",
    "                            + φ_i_k_star[i, 0]\n",
    "                            for i in range(self.num_agents))\n",
    "                                  )\n",
    "                  # Solve master problem\n",
    "                  lambda_k.start = theta_solution[:self.K_MOD-1]\n",
    "                  u_i.start = val_i\n",
    "                  model.optimize()\n",
    "                  theta_solution = np.array(model.x)\n",
    "\n",
    "                  iter += 1\n",
    "\n",
    "\n",
    "BundledChoiceKP.estimate_minmaxregret_BChoice = estimate_minmaxregret_BChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# characteristics:  5\n",
      "φ_hat_k:  [ 493.02216 1005.65173 1481.5645  2005.933   1233.1968 ]\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2562382\n",
      "Academic license 2562382 - for non-commercial use only - registered to ed___@nyu.edu\n",
      "################\n",
      "ITER: 0, parameters: [  82068.479 5877386.405 1623066.03   677831.925]\n",
      "Value of LP:    -20.141682505607605\n",
      "Reduced cost: 44868627.51104605\n",
      "################\n",
      "ITER: 1, parameters: [2041350.19  2457216.547 2481626.658 2083350.503]\n",
      "Value of LP:    -187.44222847744823\n",
      "Reduced cost: 8457128.194257714\n",
      "################\n",
      "ITER: 2, parameters: [2.061 3.051 4.077 2.591]\n",
      "Value of LP:    -493.0217455987016\n",
      "Reduced cost: 0.1129833245460361\n",
      "################\n",
      "ITER: 3, parameters: [2.004 3.007 4.01  2.506]\n",
      "Value of LP:    -493.0217528691144\n",
      "Reduced cost: 0.00012953767091516966\n",
      "################\n",
      "ITER: 4, parameters: [2.005 3.007 4.01  2.506]\n",
      "Value of LP:    -493.0217528755531\n",
      "Reduced cost: 5.125784511506026e-06\n",
      "#############################################\n",
      "#############################################\n",
      "Solution:        [2.005 3.007 4.01  2.506]\n",
      "True parameters: [2, 3, 4, 2.5]\n",
      "###############\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "# example_pb = BundledChoiceKP(250, 30, [1, 2, 3, 4, 2.5], max_capacity= 10000)\n",
    "# B_i_star = example_pb.linear_knapsack(torch.arange(example_pb.num_agents), example_pb.lambda_star)\n",
    "# example_pb.generate_data_bundle_choice()\n",
    "# example_pb.estimate_minmaxregret_BChoice(tol = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute assignment large population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_assignment_large(self, max_iters = 100 ,tol = 1e-2 ):\n",
    "#       with gp.Env(params=options) as env:\n",
    "#           with gp.Model(env=env) as model:\n",
    "#               ### Initialize\n",
    "#               # Create variables\n",
    "#               u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "#               p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "#               # Set objective and initial constraints\n",
    "#               model.setObjective( (1 / self.num_simulations) * u_si.sum() + p_j.sum(), GRB.MINIMIZE)\n",
    "              \n",
    "#               # Solve master problem \n",
    "#               model.setParam('OutputFlag', 0)\n",
    "#               model.optimize()\n",
    "#               theta_solution = np.array(model.x)\n",
    "\n",
    "#               iter = 0\n",
    "#               while iter < max_iters:\n",
    "#                   print('################')\n",
    "#                   ### Pricing problem\n",
    "#                   p_j_iter = torch.tensor(theta_solution[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "#                   B_star_si = self.linear_knapsack(\n",
    "#                                                   self.agents_si, \n",
    "#                                                   self.lambda_star, \n",
    "#                                                   eps_i_j = self.eps_si_j,\n",
    "#                                                   p_j = p_j_iter\n",
    "#                                                   )\n",
    "                 \n",
    "#                   φ_si_k_star = (self.φ_i_j_k[example_pb.agents_si] * B_star_si.unsqueeze(2)).sum(1)\n",
    "               \n",
    "#                   val_si =  φ_si_k_star @ self.lambda_star + (self.eps_si_j * B_star_si).sum(1) - (B_star_si * p_j_iter).sum(1)\n",
    "\n",
    "#                   ### Stop if certificate holds\n",
    "#                   certificate_i = val_si.cpu().numpy() - theta_solution[ : -self.num_objects]\n",
    "#                   max_certificate = np.max(certificate_i)\n",
    "\n",
    "#                   print(\"Value of LP:   \", model.objVal)\n",
    "#                   print(f\"Reduced cost: {max_certificate}\")\n",
    "\n",
    "#                   if max_certificate < tol:\n",
    "#                     print('#############################################')\n",
    "#                     print(\"SOLUTION FOUND\")\n",
    "#                     print('#############################################')\n",
    "#                     return np.array(model.x), np.array(model.pi)\n",
    "#                     break\n",
    "\n",
    "#                   ### Master problem\n",
    "#                   # Add constraints\n",
    "\n",
    "#                   B_star_si = B_star_si.cpu().numpy()\n",
    "\n",
    "#                   model.addConstrs(\n",
    "#                             (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "#                              >= φ_si_k_star[si] @ self.lambda_star\n",
    "#                             + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "#                             for si in range(self.num_simulations * self.num_agents))\n",
    "#                               )\n",
    "\n",
    "       \n",
    "#                   # Solve master problem\n",
    "                  \n",
    "#                   u_si.start = val_si.cpu().numpy() \n",
    "#                   model.optimize()\n",
    "#                   theta_solution = np.array(model.x)\n",
    "\n",
    "#                   iter += 1\n",
    "\n",
    "\n",
    "# BundledChoiceKP.compute_assignment_large = compute_assignment_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_assignment_large(self, max_iters = 100 ,tol = 1e-2 ):\n",
    "      with gp.Env(params=options) as env:\n",
    "          with gp.Model(env=env) as model:\n",
    "              ### Initialize\n",
    "              # Create variables\n",
    "              u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "              p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "              # Set objective and initial constraints\n",
    "              model.setObjective( (1 / self.num_simulations) * u_si.sum() + p_j.sum(), GRB.MINIMIZE)\n",
    "              \n",
    "              # Solve master problem \n",
    "              model.setParam('OutputFlag', 0)\n",
    "              model.optimize()\n",
    "              solution_iter = np.array(model.x)\n",
    "\n",
    "              iter = 0\n",
    "              while iter < max_iters:\n",
    "                  print('################')\n",
    "                  ### Pricing problem\n",
    "                  p_j_iter = torch.tensor(solution_iter[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "                  B_star_si, val_si = self.linear_knapsack(\n",
    "                                                  self.agents_si, \n",
    "                                                  self.lambda_star, \n",
    "                                                  eps_i_j = self.eps_si_j,\n",
    "                                                  p_j = p_j_iter,\n",
    "                                                  return_value = True\n",
    "                                                  )\n",
    "\n",
    "                  ### Stop if certificate holds\n",
    "                  certificate_i = val_si.cpu().numpy() - solution_iter[ : -self.num_objects]\n",
    "                  max_certificate = np.max(certificate_i)\n",
    "\n",
    "                  print(f\"Value of LP:  {model.objVal}\")\n",
    "                  print(f\"Reduced cost: {max_certificate}\")\n",
    "\n",
    "                  if max_certificate < tol:\n",
    "                    print('#############################################')\n",
    "                    print(\"SOLUTION FOUND\")\n",
    "                    print('#############################################')\n",
    "                    return np.array(model.x), np.array(model.pi), iter +1\n",
    "\n",
    "                  ### Master problem\n",
    "                  # Add constraints\n",
    "                  Φ_si_B_star = val_si + (B_star_si * p_j_iter).sum(1)\n",
    "                  B_star_si = B_star_si.cpu().numpy()\n",
    "\n",
    "                  model.addConstrs(\n",
    "                                  (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "                                  >= Φ_si_B_star[si]\n",
    "                                  for si in range(self.num_simulations * self.num_agents))\n",
    "                                  )\n",
    "                  \n",
    "                  # Solve master problem\n",
    "                  u_si.start = val_si.cpu().numpy() \n",
    "                  p_j.start = p_j_iter.cpu().numpy()\n",
    "                  model.optimize()\n",
    "                  solution_iter = np.array(model.x)\n",
    "                  \n",
    "                  iter += 1\n",
    "\n",
    "\n",
    "BundledChoiceKP.compute_assignment_large = compute_assignment_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_pb = BundledChoiceKP(10, 30, [1, 2, 3, 4, 2.5], num_simulations= 30, max_capacity= 200)\n",
    "# primal_solution, dual_solution , iters = example_pb.compute_assignment_large()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estimate_GMM_matching(self, max_iters = 100, tol = 1e-2 ):\n",
    "#       with gp.Env(params=options) as env:\n",
    "#           with gp.Model(env=env) as model:\n",
    "#               ### Initialize\n",
    "#               # Create variables\n",
    "#               lambda_k = model.addVars(self.K_MOD , lb= 0, ub = 1e6 , name=\"parameters\")\n",
    "#               u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "#               p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "#               # Set objective and initial constraints\n",
    "#               model.setObjective(gp.quicksum( self.φ_hat_k[k] * lambda_k[k] for k in range(self.K_MOD ))\n",
    "#                                   - (1 / self.num_simulations) * u_si.sum() - p_j.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "#               # model.addConstrs(\n",
    "#               #                 (u_si[si] + gp.quicksum(p_j[j] for j in np.where(self.B_i_j_hat[si // self.num_simulations])[0])\n",
    "#               #                 >= gp.quicksum((self.φ_hat_i_k[si // self.num_simulations, k]) * lambda_k[k]  for k in range(self.K_MOD))\n",
    "#               #                 + self.eps_si_j[si, self.B_i_j_hat[si // self.num_simulations]].sum()\n",
    "#               #                 for si in range(self.num_simulations * self.num_agents))\n",
    "#               #                 )\n",
    "              \n",
    "#               # Solve master problem \n",
    "#               model.setParam('OutputFlag', 0)\n",
    "#               model.optimize()\n",
    "#               solution_iter = np.array(model.x)\n",
    "\n",
    "#               iter = 0\n",
    "#               while iter < max_iters:\n",
    "#                   print('################')\n",
    "#                   print(f\"ITER: {iter}, parameters: {solution_iter[:self.K_MOD].round(3)}\")\n",
    "\n",
    "#                   ### Pricing problem\n",
    "#                   lambda_k_iter = torch.tensor(solution_iter[:self.K_MOD], device= device , dtype=torch.float32)\n",
    "#                   p_j_iter = torch.tensor(solution_iter[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "#                   B_star_si, val_si = self.linear_knapsack(\n",
    "#                                                   self.agents_si, \n",
    "#                                                   lambda_k_iter, \n",
    "#                                                   eps_i_j = self.eps_si_j,\n",
    "#                                                   p_j = p_j_iter,\n",
    "#                                                   return_value = True\n",
    "#                                                   )\n",
    "\n",
    "#                   ### Stop if certificate holds\n",
    "#                   certificate_i = val_si.cpu().numpy() - solution_iter[self.K_MOD: - self.num_objects]\n",
    "#                   max_certificate = np.max(certificate_i)\n",
    "\n",
    "#                   print(\"Value of LP:   \", model.objVal)\n",
    "#                   print(f\"Reduced cost: {max_certificate}\")\n",
    "#                   if max_certificate < tol:\n",
    "#                     print('#############################################')\n",
    "#                     print(\"Solution:       \", solution_iter[:self.K_MOD].round(3))\n",
    "#                     print(\"True parameters:\", self.lambda_star_np)\n",
    "#                     print('#############################################')\n",
    "#                     break\n",
    "\n",
    "#                   ### Master problem\n",
    "#                   # Add constraints\n",
    "#                   φ_si_k_star = (self.φ_i_j_k[self.agents_si] * B_star_si.unsqueeze(2)).sum(1)\n",
    "#                   B_star_si = B_star_si.cpu().numpy()\n",
    "\n",
    "#                   model.addConstrs(\n",
    "#                                   (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "#                                   >= gp.quicksum((φ_si_k_star[si, k]) * lambda_k[k]  for k in range(self.K_MOD))\n",
    "#                                   + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "#                                   for si in range(self.num_simulations * self.num_agents))\n",
    "#                                   )\n",
    "                  \n",
    "#                   # Solve master problem\n",
    "#                   lambda_k.start = solution_iter[ : self.K_MOD]\n",
    "#                   p_j.start = p_j_iter.cpu().numpy()\n",
    "#                   u_si.start = val_si.cpu().numpy() \n",
    "\n",
    "#                   model.optimize()\n",
    "#                   solution_iter = np.array(model.x)\n",
    "\n",
    "#                   iter += 1\n",
    "\n",
    "# BundledChoiceKP.estimate_GMM_matching = estimate_GMM_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_GMM_matching(self, max_iters = 100, tol = 1e-2 ):\n",
    "      with gp.Env(params=options) as env:\n",
    "          with gp.Model(env=env) as model:\n",
    "              ### Initialize\n",
    "              # Create variables\n",
    "              lambda_k = model.addVars(self.K_MOD , lb= 0, ub = 1e6 , name=\"parameters\")\n",
    "              u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "              p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "              # Set objective and initial constraints\n",
    "              model.setObjective(gp.quicksum( self.φ_hat_k[k] * lambda_k[k] for k in range(self.K_MOD ))\n",
    "                                  - (1 / self.num_simulations) * u_si.sum() - p_j.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "              # Solve master problem \n",
    "              model.setParam('OutputFlag', 0)\n",
    "              model.optimize()\n",
    "              solution_iter = np.array(model.x)\n",
    "\n",
    "              iter = 0\n",
    "              while iter < max_iters:\n",
    "                  print('################')\n",
    "                  print(f\"ITER: {iter}, parameters: {solution_iter[:self.K_MOD]}\")\n",
    "          \n",
    "                  ### Pricing problem\n",
    "                  lambda_k_iter = torch.tensor(solution_iter[:self.K_MOD], device= device , dtype=torch.float32)\n",
    "                  p_j_iter = torch.tensor(solution_iter[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "                  B_star_si, val_si = self.linear_knapsack(\n",
    "                                                            self.agents_si, \n",
    "                                                            lambda_k_iter, \n",
    "                                                            eps_i_j = self.eps_si_j,\n",
    "                                                            p_j = p_j_iter,\n",
    "                                                            return_value = True\n",
    "                                                            )\n",
    "\n",
    "                  ### Stop if certificate holds\n",
    "                  certificate_i = val_si.cpu().numpy() - solution_iter[self.K_MOD: - self.num_objects]\n",
    "                  max_certificate = np.max(certificate_i)\n",
    "\n",
    "                  print(\"Value of LP:   \", model.objVal)\n",
    "                  print(f\"Reduced cost: {max_certificate}\")\n",
    "                  if max_certificate < tol:\n",
    "                        print('#############################################')\n",
    "                        print(\"Solution:       \", solution_iter[:self.K_MOD].round(3))\n",
    "                        print(\"True parameters:\", self.lambda_star_np)\n",
    "                        print('#############################################')\n",
    "                        return solution_iter\n",
    "\n",
    "                  ### Master problem\n",
    "                  # Add constraints\n",
    "                  φ_si_k_star = (self.φ_i_j_k[self.agents_si] * B_star_si.unsqueeze(2)).sum(1)\n",
    "                  B_star_si = B_star_si.cpu().numpy()\n",
    "\n",
    "                  model.addConstrs(\n",
    "                                  (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "                                  >= gp.quicksum((φ_si_k_star[si, k]) * lambda_k[k]  for k in range(self.K_MOD))\n",
    "                                  + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "                                  for si in range(self.num_simulations * self.num_agents))\n",
    "                                  )\n",
    "                  \n",
    "                  # Solve master problem\n",
    "                  lambda_k.start = solution_iter[ : self.K_MOD]\n",
    "                  p_j.start = p_j_iter.cpu().numpy()\n",
    "                  u_si.start = val_si.cpu().numpy() \n",
    "\n",
    "                  model.optimize()\n",
    "                  solution_iter = np.array(model.x)\n",
    "\n",
    "                  iter += 1\n",
    "\n",
    "BundledChoiceKP.estimate_GMM_matching = estimate_GMM_matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
