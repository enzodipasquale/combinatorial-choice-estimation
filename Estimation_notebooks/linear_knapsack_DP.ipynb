{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:  True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "import itertools\n",
    "from itertools import product\n",
    "import torch\n",
    "\n",
    "print('mps: ', torch.backends.mps.is_available())\n",
    "\n",
    "options = {\n",
    " \"WLSACCESSID\":\"a4353fb7-f95b-4075-b288-ca3f60983b36\",\n",
    "\"WLSSECRET\":\"d894d460-2dac-4210-8c40-c91c68ecfb13\",\n",
    "\"LICENSEID\":2562382\n",
    "}\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use the Metal backend\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BundledChoiceKP:\n",
    "    def __init__(self,  num_agents , num_objects , lambda_star , random_seed = 4,  sigma = 1, max_capacity = 100):\n",
    "\n",
    "        self.K_MOD = len(lambda_star)\n",
    "        self.num_agents = num_agents\n",
    "        self.num_objects = num_objects\n",
    "        self.num_simulations = 100\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.agents_si = torch.kron(torch.ones(self.num_simulations, dtype = torch.int), torch.arange(self.num_agents))\n",
    "\n",
    "\n",
    "        # Initialize stuff\n",
    "   \n",
    "\n",
    "        # True parameters\n",
    "        self.lambda_star_np = lambda_star\n",
    "        self.lambda_star = torch.tensor(lambda_star, device=device, dtype=torch.float)\n",
    "\n",
    "        # Set manual seed\n",
    "        torch.manual_seed(self.random_seed)\n",
    "\n",
    "        ### Modular characteristics\n",
    "        self.φ_i_j_k = torch.normal(0, 1, size=(self.num_agents, self.num_objects, self.K_MOD), device=device, dtype=torch.float)\n",
    "\n",
    "        ### Knapsack Constraints\n",
    "        self.weight_j = torch.randint(1, 100, (self.num_objects,), device=device, dtype = torch.int)\n",
    "        self.capacity_i = torch.randint(1, max_capacity, (self.num_agents,), device=device, dtype=torch.int) \n",
    "        \n",
    "    \n",
    "        ### estimation\n",
    "        self.φ_hat_k = None\n",
    "        self.φ_hat_i_k = None\n",
    "        self.value_LP = None\n",
    "\n",
    "        self.eps_i_j = sigma * torch.normal(0, 1, size=(self.num_agents, self.num_objects), device=device, dtype=torch.float)\n",
    "        self.eps_si_j = sigma * torch.normal(0, 1, size=(self.num_simulations * self.num_agents, self.num_objects), device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_knapsack(self, idx, lambda_k , max_weight = None, p_j = None, eps_i_j = None):\n",
    "    \n",
    "    ### Compute the values\n",
    "    values_i_j = self.φ_i_j_k[idx]  @  lambda_k \n",
    "\n",
    "    if p_j is not None:\n",
    "        values_i_j -= p_j.unsqueeze(0)\n",
    "    if eps_i_j is not None:\n",
    "        values_i_j += eps_i_j\n",
    "\n",
    "    if max_weight is None:\n",
    "        max_weight = int(self.capacity_i[idx].max())\n",
    "    \n",
    "    ### Fill in the DP table\n",
    "    V_i_j_w = torch.zeros((len(idx), self.num_objects +1, max_weight +1) ,device=device, dtype=torch.float)\n",
    "    weight_states = torch.arange(max_weight + 1, device= device)\n",
    "\n",
    "    for j in range(self.num_objects):\n",
    "        V_i_j_w[:, j+1, :] = torch.where(self.weight_j[j] <= weight_states, \n",
    "                                    torch.maximum(values_i_j[:, j].unsqueeze(1) + V_i_j_w[:, j, weight_states - self.weight_j[j]],\n",
    "                                                V_i_j_w[:, j, :]), \n",
    "                                        V_i_j_w[:, j, :])\n",
    "        \n",
    "    # print(V_i_j_w[torch.arange(len(idx)),-1, self.capacity_i[idx]])\n",
    "\n",
    "    ### Backtrack to find the items\n",
    "    residual_weight = self.capacity_i[idx]\n",
    "    B_i_j_star = torch.zeros((len(idx), self.num_objects), device=device, dtype= bool)\n",
    "\n",
    "    for j in range(self.num_objects,0,-1):\n",
    "\n",
    "        pick_j = (V_i_j_w[torch.arange(len(idx)), j, residual_weight] > \n",
    "                    V_i_j_w[torch.arange(len(idx)), j-1, residual_weight])\n",
    "        \n",
    "        B_i_j_star[:, j-1] = pick_j\n",
    "        residual_weight -= pick_j * self.weight_j[j-1]\n",
    "        #residual_weight = torch.clamp(residual_weight, min=0)\n",
    "    \n",
    "    # print((values_i_j * B_i_j_star).sum(1))\n",
    "\n",
    "    return B_i_j_star \n",
    "\n",
    "BundledChoiceKP.linear_knapsack = linear_knapsack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(self, add_noise = False):\n",
    "\n",
    "    noise = self.eps_i_j if add_noise else None\n",
    "\n",
    "    B_i_j_star = self.linear_knapsack(torch.arange(self.num_agents), self.lambda_star, eps_i_j = noise)\n",
    "\n",
    "    self.φ_hat_i_k = (self.φ_i_j_k * B_i_j_star.unsqueeze(2)).sum(1)\n",
    "    self.φ_hat_k = self.φ_hat_i_k.sum(0)\n",
    "\n",
    "    print(\"# characteristics: \",self.K_MOD)\n",
    "    print(\"φ_hat_k: \", self.φ_hat_k.cpu().numpy())\n",
    "\n",
    "BundledChoiceKP.generate_data = generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pb = BundledChoiceKP( 10, 30, [1, 2, 3, 4, 2.5], max_capacity= 200)\n",
    "# B_i_star = example_pb.linear_knapsack(torch.arange(500), example_pb.lambda_star)\n",
    "# example_pb.generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_minmaxregret_BChoice(self, max_iters = 100 ,tol = 1e-2 ):\n",
    "      with gp.Env(params=options) as env:\n",
    "          with gp.Model(env=env) as model:\n",
    "              ### Initialize\n",
    "              # Create variables\n",
    "              lambda_k = model.addVars(self.K_MOD - 1, lb= 0, ub = 1e8 , name=\"parameters\")\n",
    "              u_i = model.addVars(self.num_agents, lb = 0, ub = 1e8 , name=\"utilities\")\n",
    "\n",
    "              # Set objective and initial constraints\n",
    "              model.setObjective(gp.quicksum( self.φ_hat_k[k+1] * lambda_k[k] for k in range(self.K_MOD - 1))\n",
    "                                  - u_i.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "              model.addConstrs(\n",
    "                            (u_i[i] >= gp.quicksum((self.φ_hat_i_k[i, k+1]) * lambda_k[k]  for k in range(self.K_MOD - 1))\n",
    "                            + self.φ_hat_i_k[i, 0]\n",
    "                            for i in range(self.num_agents))\n",
    "                              )\n",
    "              \n",
    "              # Solve master problem \n",
    "              model.setParam('OutputFlag', 0)\n",
    "              model.optimize()\n",
    "              theta_solution = np.array(model.x)\n",
    "\n",
    "              iter = 0\n",
    "              while iter < max_iters:\n",
    "                  print('################')\n",
    "                  print(f\"ITER: {iter}, parameters: {theta_solution[:self.K_MOD-1].round(3)}\")\n",
    "\n",
    "                  ### Pricing problem\n",
    "                  lambda_k_iter = torch.cat((torch.tensor([1.0], device= device),\n",
    "                                               torch.tensor(theta_solution[:self.K_MOD-1], device= device , dtype=torch.float32)))\n",
    "\n",
    "\n",
    "                  B_star_i = self.linear_knapsack(torch.arange(self.num_agents), lambda_k_iter)\n",
    "\n",
    "                  val_i =  (self.φ_i_j_k * B_star_i.unsqueeze(2)).sum(1) @ lambda_k_iter\n",
    "\n",
    "                  ### Stop if certificate holds\n",
    "                  certificate_i = val_i.cpu().numpy() - theta_solution[self.K_MOD-1:]\n",
    "                  max_certificate = np.max(certificate_i)\n",
    "\n",
    "                  print(\"Value of LP:   \", model.objVal)\n",
    "                  print(f\"Reduced cost: {max_certificate}\")\n",
    "\n",
    "                  if max_certificate < tol:\n",
    "                    primal_solution = np.array(model.x)\n",
    "                    dual_solution = np.array(model.pi)\n",
    "                    print('#############################################')\n",
    "                    print('#############################################')\n",
    "                    print(\"Solution:       \", primal_solution[:self.K_MOD-1].round(3))\n",
    "                    print(\"True parameters:\", self.lambda_star_np[1:])\n",
    "                    print('###############')\n",
    "                    # print(\"Value of LP:   \", model.objVal)\n",
    "                    # print(\"True value LP: \",self.value_LP)\n",
    "                    print('#############################################')\n",
    "                    # print('#############################################')\n",
    "                    break\n",
    "\n",
    "                  ### Master problem\n",
    "                  # Add constraints\n",
    "\n",
    "                  φ_i_k_star = (self.φ_i_j_k * B_star_i.unsqueeze(2)).sum(1)\n",
    "\n",
    "                  model.addConstrs(\n",
    "                            (u_i[i] >= gp.quicksum((φ_i_k_star[i, k+1]) * lambda_k[k]  for k in range(self.K_MOD - 1))\n",
    "                            + φ_i_k_star[i, 0]\n",
    "                            for i in range(self.num_agents))\n",
    "                                  )\n",
    "                  # Solve master problem\n",
    "                  lambda_k.start = theta_solution[:self.K_MOD-1]\n",
    "                  u_i.start = val_i\n",
    "                  model.optimize()\n",
    "                  theta_solution = np.array(model.x)\n",
    "\n",
    "                  iter += 1\n",
    "\n",
    "\n",
    "BundledChoiceKP.estimate_minmaxregret_BChoice = estimate_minmaxregret_BChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_pb.estimate_minmaxregret_BChoice(tol = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_GMM_matching(self, max_iters = 100 ,tol = 1e-2 ):\n",
    "      with gp.Env(params=options) as env:\n",
    "          with gp.Model(env=env) as model:\n",
    "              ### Initialize\n",
    "              # Create variables\n",
    "              lambda_k = model.addVars(self.K_MOD , lb= 0, ub = 1e6 , name=\"parameters\")\n",
    "              u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "              p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "              # Set objective and initial constraints\n",
    "              model.setObjective(gp.quicksum( self.φ_hat_k[k] * lambda_k[k] for k in range(self.K_MOD ))\n",
    "                                  - (1 / self.num_simulations) * u_si.sum() - p_j.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "              model.addConstrs(\n",
    "                            (u_si[si] + gp.quicksum(p_j[j] for j in np.where(self.B_i_j_hat[si // self.num_simulations])[0])\n",
    "                             >= gp.quicksum((self.φ_hat_i_k[si // self.num_simulations, k]) * lambda_k[k]  for k in range(self.K_MOD))\n",
    "                            + self.eps_si_j[si, self.B_i_j_hat[si // self.num_simulations]].sum()\n",
    "                            for si in range(self.num_simulations * self.num_agents))\n",
    "                            )\n",
    "              \n",
    "              # Solve master problem \n",
    "              model.setParam('OutputFlag', 0)\n",
    "              model.optimize()\n",
    "              theta_solution = np.array(model.x)\n",
    "\n",
    "              iter = 0\n",
    "              while iter < max_iters:\n",
    "                  print('################')\n",
    "                  print(f\"ITER: {iter}, parameters: {theta_solution[:self.K_MOD].round(3)}\")\n",
    "\n",
    "                  ### Pricing problem\n",
    "                  lambda_k_iter = torch.tensor(theta_solution[:self.K_MOD], device= device , dtype=torch.float32)\n",
    "                  p_j_iter = torch.tensor(theta_solution[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "                  B_star_si = self.linear_knapsack(\n",
    "                                                  self.agents_si, \n",
    "                                                  lambda_k_iter, \n",
    "                                                  eps_i_j = self.eps_si_j,\n",
    "                                                  p_j = p_j_iter\n",
    "                                                  )\n",
    "                  \n",
    "                  φ_si_k_star = (self.φ_i_j_k[example_pb.agents_si] * B_star_si.unsqueeze(2)).sum(1)\n",
    "\n",
    "                  val_si =  φ_si_k_star @ lambda_k_iter\n",
    "\n",
    "                  ### Stop if certificate holds\n",
    "                  certificate_i = val_si.cpu().numpy() - theta_solution[self.K_MOD: -self.num_objects]\n",
    "                  max_certificate = np.max(certificate_i)\n",
    "\n",
    "                  print(\"Value of LP:   \", model.objVal)\n",
    "                  print(f\"Reduced cost: {max_certificate}\")\n",
    "\n",
    "                  if max_certificate < tol:\n",
    "                    primal_solution = np.array(model.x)\n",
    "                    dual_solution = np.array(model.pi)\n",
    "                    print('#############################################')\n",
    "                    print('#############################################')\n",
    "                    print(\"Solution:       \", primal_solution[:self.K_MOD].round(3))\n",
    "                    print(\"True parameters:\", self.lambda_star_np)\n",
    "                    print('###############')\n",
    "                    # print(\"Value of LP:   \", model.objVal)\n",
    "                    # print(\"True value LP: \",self.value_LP)\n",
    "                    print('#############################################')\n",
    "                    # print('#############################################')\n",
    "                    break\n",
    "\n",
    "                  ### Master problem\n",
    "                  # Add constraints\n",
    "\n",
    "                  # φ_i_k_star = (self.φ_i_j_k * B_star_i.unsqueeze(2)).sum(1)\n",
    "\n",
    "                  model.addConstrs(\n",
    "                            (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "                             >= gp.quicksum((φ_si_k_star[si, k]) * lambda_k[k]  for k in range(self.K_MOD ))\n",
    "                            + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "                            for si in range(self.num_simulations * self.num_agents))\n",
    "                              )\n",
    "                  # Solve master problem\n",
    "                  lambda_k.start = theta_solution[ : self.K_MOD]\n",
    "                  u_si.start = val_si.cpu().numpy() \n",
    "                  model.optimize()\n",
    "                  theta_solution = np.array(model.x)\n",
    "\n",
    "                  iter += 1\n",
    "\n",
    "\n",
    "BundledChoiceKP.estimate_GMM_matching = estimate_GMM_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_assignment_large(self, max_iters = 100 ,tol = 1e-2 ):\n",
    "      with gp.Env(params=options) as env:\n",
    "          with gp.Model(env=env) as model:\n",
    "              ### Initialize\n",
    "              # Create variables\n",
    "              u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "              p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "              # Set objective and initial constraints\n",
    "              model.setObjective( (1 / self.num_simulations) * u_si.sum() + p_j.sum(), GRB.MINIMIZE)\n",
    "              \n",
    "              # Solve master problem \n",
    "              model.setParam('OutputFlag', 0)\n",
    "              model.optimize()\n",
    "              theta_solution = np.array(model.x)\n",
    "\n",
    "              iter = 0\n",
    "              while iter < max_iters:\n",
    "                  print('################')\n",
    "                  ### Pricing problem\n",
    "                  p_j_iter = torch.tensor(theta_solution[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "                  B_star_si = self.linear_knapsack(\n",
    "                                                  self.agents_si, \n",
    "                                                  self.lambda_star, \n",
    "                                                  eps_i_j = self.eps_si_j,\n",
    "                                                  p_j = p_j_iter\n",
    "                                                  )\n",
    "                 \n",
    "                  φ_si_k_star = (self.φ_i_j_k[example_pb.agents_si] * B_star_si.unsqueeze(2)).sum(1)\n",
    "               \n",
    "                  val_si =  φ_si_k_star @ self.lambda_star + (self.eps_si_j * B_star_si).sum(1) - (B_star_si * p_j_iter).sum(1)\n",
    "\n",
    "                  ### Stop if certificate holds\n",
    "                  certificate_i = val_si.cpu().numpy() - theta_solution[ : -self.num_objects]\n",
    "                  max_certificate = np.max(certificate_i)\n",
    "\n",
    "                  print(\"Value of LP:   \", model.objVal)\n",
    "                  print(f\"Reduced cost: {max_certificate}\")\n",
    "\n",
    "                  if max_certificate < tol:\n",
    "                    print('#############################################')\n",
    "                    print(\"DONE\")\n",
    "                    return np.array(model.x), np.array(model.pi)\n",
    "                    print('#############################################')\n",
    "                    break\n",
    "\n",
    "                  ### Master problem\n",
    "                  # Add constraints\n",
    "                  B_star_si = B_star_si.cpu().numpy()\n",
    "                  \n",
    "                  model.addConstrs(\n",
    "                            (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "                             >= φ_si_k_star[si] @ self.lambda_star\n",
    "                            + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "                            for si in range(self.num_simulations * self.num_agents))\n",
    "                              )\n",
    "                  \n",
    "                  # Solve master problem\n",
    "                  \n",
    "                  u_si.start = val_si.cpu().numpy() \n",
    "                  model.optimize()\n",
    "                  theta_solution = np.array(model.x)\n",
    "\n",
    "                  iter += 1\n",
    "\n",
    "\n",
    "BundledChoiceKP.compute_assignment_large = compute_assignment_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2562382\n",
      "Academic license 2562382 - for non-commercial use only - registered to ed___@nyu.edu\n",
      "################\n",
      "Value of LP:    0.0\n",
      "Reduced cost: 52.910423278808594\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    94.53053581237793\n",
      "Reduced cost: 32.1856803894043\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    153.233761947155\n",
      "Reduced cost: 30.195255279541016\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    170.34780642032615\n",
      "Reduced cost: 18.32301139831543\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    193.46719916343696\n",
      "Reduced cost: 7.370992660522461\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    200.54177273750304\n",
      "Reduced cost: 2.295408248901367\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    200.88439765453347\n",
      "Reduced cost: 0.9164137840270996\n",
      "begin add constraints\n",
      "end add constraints\n",
      "################\n",
      "Value of LP:    200.9113008952142\n",
      "Reduced cost: 5.245208740234375e-06\n",
      "#############################################\n",
      "DONE\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "primal_solution, dual_solution = example_pb.compute_assignment_large()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
