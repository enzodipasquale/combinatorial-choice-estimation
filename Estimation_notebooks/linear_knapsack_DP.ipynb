{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:  True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "import itertools\n",
    "from itertools import product\n",
    "import torch\n",
    "\n",
    "print('mps: ', torch.backends.mps.is_available())\n",
    "\n",
    "options = {\n",
    " \"WLSACCESSID\":\"a4353fb7-f95b-4075-b288-ca3f60983b36\",\n",
    "\"WLSSECRET\":\"d894d460-2dac-4210-8c40-c91c68ecfb13\",\n",
    "\"LICENSEID\":2562382\n",
    "}\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use the Metal backend\n",
    "else:\n",
    "    device = torch.device(\"cuda\")  # Fallback to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BundledChoiceKP:\n",
    "    def __init__(self,  num_agents , num_objects , lambda_star = None, num_simulations = 20, \n",
    "                 random_seed = 4,  sigma = 1, max_capacity = 100, generate_data = True):\n",
    "\n",
    "        self.num_agents = num_agents\n",
    "        self.num_objects = num_objects\n",
    "        self.num_simulations = num_simulations\n",
    "\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "        torch.manual_seed(self.random_seed)\n",
    "        self.device = device\n",
    "        self.agents_i = torch.arange(self.num_agents)\n",
    "        self.agents_si = torch.kron(torch.ones(self.num_simulations, dtype = torch.int), torch.arange(self.num_agents))\n",
    "\n",
    "        \n",
    "        if lambda_star is not None:           \n",
    "            # True parameters\n",
    "            self.K_MOD = len(lambda_star)\n",
    "            self.lambda_star_np = lambda_star\n",
    "            self.lambda_star = torch.tensor(lambda_star, device=device, dtype=torch.float)\n",
    "\n",
    "        else:                                 \n",
    "            self.K_MOD = None\n",
    "            self.lambda_star_np = None\n",
    "            self.lambda_star = None\n",
    "\n",
    "        if generate_data is True:\n",
    "            ### Modular characteristics\n",
    "            self.φ_i_j_k_numpy = np.random.normal(0, 1, (self.num_agents, self.num_objects, self.K_MOD))\n",
    "            self.φ_i_j_k = torch.tensor(self.φ_i_j_k_numpy, device=device, dtype=torch.float) \n",
    "\n",
    "            # self.φ_i_j_k = torch.normal(0, 1, size=(self.num_agents, self.num_objects, self.K_MOD), \n",
    "            #                             device=device, dtype=torch.float)\n",
    "\n",
    "            ### Knapsack Constraints\n",
    "            self.weight_j = torch.randint(1, 100, (self.num_objects,), device=device, dtype = torch.int)\n",
    "            self.capacity_i = torch.randint(1, max_capacity, (self.num_agents,), device=device, dtype=torch.int) \n",
    "        else:\n",
    "            self.φ_i_j_k_numpy = None\n",
    "            self.φ_i_j_k = None\n",
    "            self.weight_j = None\n",
    "            self.capacity_i = None\n",
    "        \n",
    "    \n",
    "        ### Estimation\n",
    "        self.φ_hat_k = None\n",
    "        self.φ_hat_i_k = None\n",
    "        self.value_LP = None\n",
    "\n",
    "        self.eps_i_j = sigma * torch.normal(0, 1, size=(self.num_agents, self.num_objects), device=device, dtype=torch.float)\n",
    "        self.eps_si_j = sigma * torch.normal(0, 1, size=(self.num_simulations * self.num_agents, self.num_objects), \n",
    "                                             device=device, dtype=torch.float)\n",
    "        self.eps_s_i_j = self.eps_si_j.reshape(self.num_simulations, self.num_agents, self.num_objects)\n",
    "\n",
    "    def load_data(self, characteristic_i_j, weight_j, capacity_i, matching_i_j):\n",
    "        \n",
    "        # Modular characteristics\n",
    "        self.φ_i_j_k_numpy = characteristic_i_j\n",
    "        self.φ_i_j_k  = torch.tensor(characteristic_i_j, dtype=torch.float32, device=self.device)\n",
    "        self.K_MOD = self.φ_i_j_k.size(2)\n",
    "\n",
    "        # Weights and capacities\n",
    "        self.weight_j = torch.tensor(weight_j, dtype=torch.int64, device=self.device)\n",
    "        self.capacity_i = torch.tensor(capacity_i, dtype=torch.int64, device=self.device)\n",
    "       \n",
    "        # Observed moments from matching\n",
    "        self.φ_hat_k = (self.φ_i_j_k_numpy * matching_i_j[:,:,None]).sum((0,1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_knapsack(self, idx, lambda_k , max_weight = None, p_j = None, eps_i_j = None, return_value = False):\n",
    "    \n",
    "    ### Compute the values\n",
    "    profit_i_j = self.φ_i_j_k[idx]  @  lambda_k \n",
    "\n",
    "    if p_j is not None:\n",
    "        profit_i_j -= p_j.unsqueeze(0)\n",
    "    if eps_i_j is not None:\n",
    "        profit_i_j += eps_i_j\n",
    "\n",
    "    if max_weight is None:\n",
    "        max_weight = int(self.capacity_i[idx].max())\n",
    "    \n",
    "    ### Fill in the DP table\n",
    "    value_i_j_w = torch.zeros((len(idx), self.num_objects +1, max_weight +1) ,device=device, dtype=torch.float)\n",
    "    weight_states = torch.arange(max_weight + 1, device = device)\n",
    "\n",
    "    # print type of weight_states\n",
    "    for j in range(self.num_objects):\n",
    "        value_i_j_w[:, j+1, :] = torch.where(self.weight_j[j] <= weight_states, \n",
    "                                    torch.maximum(profit_i_j[:, j].unsqueeze(1) + value_i_j_w[:, j, weight_states - self.weight_j[j]],\n",
    "                                                value_i_j_w[:, j, :]), \n",
    "                                        value_i_j_w[:, j, :])\n",
    "\n",
    "    ### Backtrack to find the items\n",
    "    residual_weight = self.capacity_i[idx]\n",
    "    B_i_j_star = torch.zeros((len(idx), self.num_objects), device=device, dtype= bool)\n",
    "\n",
    "    for j in range(self.num_objects,0,-1):\n",
    "\n",
    "        pick_j = (value_i_j_w[torch.arange(len(idx)), j, residual_weight] > \n",
    "                    value_i_j_w[torch.arange(len(idx)), j-1, residual_weight])\n",
    "        \n",
    "        B_i_j_star[:, j-1] = pick_j\n",
    "        residual_weight -= pick_j * self.weight_j[j-1]\n",
    "\n",
    "    if return_value:\n",
    "        return B_i_j_star, value_i_j_w[torch.arange(len(idx)), -1 , self.capacity_i[idx]]\n",
    "    else:\n",
    "        return B_i_j_star \n",
    "\n",
    "BundledChoiceKP.linear_knapsack = linear_knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_GMM_matching(self, max_iters = 100, tol = 1e-2 ):\n",
    "\n",
    "                ### Initialize\n",
    "                env = gp.Env(params=options) \n",
    "                model = gp.Model(env=env) \n",
    "                # Create variables\n",
    "                lambda_k = model.addVars(self.K_MOD , lb= 0, ub = 1e6 , name=\"parameters\")\n",
    "                u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "                p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "                # Set objective and initial constraints\n",
    "                model.setObjective(gp.quicksum( self.φ_hat_k[k] * lambda_k[k] for k in range(self.K_MOD ))\n",
    "                                    - (1 / self.num_simulations) * u_si.sum() - p_j.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "                # Solve master problem \n",
    "                model.setParam('OutputFlag', 0)\n",
    "                model.optimize()\n",
    "                solution_master_pb = np.array(model.x)\n",
    "\n",
    "                iter = 0\n",
    "                while iter < max_iters:\n",
    "                    print('################')\n",
    "                    print(f\"ITER: {iter}, parameters: {solution_master_pb[:self.K_MOD]}\")\n",
    "            \n",
    "                    ### Pricing problem\n",
    "                    lambda_k_iter = torch.tensor(solution_master_pb[:self.K_MOD], device= device , dtype=torch.float32)\n",
    "                    p_j_iter = torch.tensor(solution_master_pb[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "\n",
    "                    B_star_si, val_si = self.linear_knapsack(\n",
    "                                                                self.agents_si, \n",
    "                                                                lambda_k_iter, \n",
    "                                                                eps_i_j = self.eps_si_j,\n",
    "                                                                p_j = p_j_iter,\n",
    "                                                                return_value = True\n",
    "                                                                )\n",
    "\n",
    "                    ### Stop if certificate holds\n",
    "                    certificate_i = val_si.cpu().numpy() - solution_master_pb[self.K_MOD: - self.num_objects]\n",
    "                    max_certificate = np.max(certificate_i)\n",
    "\n",
    "                    print(\"Value of LP:   \", model.objVal)\n",
    "                    print(f\"Reduced cost: {max_certificate}\")\n",
    "                    if max_certificate < tol:\n",
    "                            print('#############################################')\n",
    "                            print(\"Solution:       \", solution_master_pb[:self.K_MOD].round(3))\n",
    "                            if self.lambda_star_np is not None:\n",
    "                                print(\"True parameters:\", self.lambda_star_np)\n",
    "                            print('Number of iterations: ', iter)\n",
    "                            print('#############################################')\n",
    "                            return solution_master_pb , np.array(model.pi)\n",
    "\n",
    "                    ### Master problem\n",
    "                    # Add constraints\n",
    "                    B_star_si = B_star_si.cpu().numpy()\n",
    "                    φ_si_k_star = (self.φ_i_j_k_numpy[self.agents_si] * B_star_si[:,:,None]).sum(1)\n",
    "                    \n",
    "                    model.addConstrs(\n",
    "                                    (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "                                    >= gp.quicksum((φ_si_k_star[si, k]) * lambda_k[k]  for k in range(self.K_MOD))\n",
    "                                    + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "                                    for si in range(self.num_simulations * self.num_agents))\n",
    "                                    )\n",
    "                    \n",
    "                    # Solve master problem\n",
    "                    lambda_k.start = solution_master_pb[ : self.K_MOD]\n",
    "                    p_j.start = p_j_iter.cpu().numpy()\n",
    "                    u_si.start = val_si.cpu().numpy() \n",
    "\n",
    "                    model.optimize()\n",
    "                    solution_master_pb = np.array(model.x)\n",
    "\n",
    "                    iter += 1\n",
    "        \n",
    "\n",
    "BundledChoiceKP.estimate_GMM_matching = estimate_GMM_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_GMM_matching_batched(self, max_iters = 100, tol = 1e-2 ):\n",
    "                env = gp.Env(params=options) \n",
    "                model = gp.Model(env=env) \n",
    "                ### Initialize\n",
    "                # Create variables\n",
    "                lambda_k = model.addVars(self.K_MOD , lb= -1e6, ub = 1e6 , name=\"parameters\")\n",
    "                u_si = model.addVars(self.num_simulations * self.num_agents, lb = 0, ub = GRB.INFINITY , name=\"utilities\")\n",
    "                p_j = model.addVars(self.num_objects, lb = 0, ub = GRB.INFINITY , name=\"prices\")\n",
    "\n",
    "                # Set objective and initial constraints\n",
    "                model.setObjective(gp.quicksum( self.φ_hat_k[k] * lambda_k[k] for k in range(self.K_MOD ))\n",
    "                                    - (1 / self.num_simulations) * u_si.sum() - p_j.sum(), GRB.MAXIMIZE)\n",
    "\n",
    "                # Solve master problem \n",
    "                model.setParam('OutputFlag', 0)\n",
    "                model.optimize()\n",
    "                solution_master_pb = np.array(model.x)\n",
    "\n",
    "                iter = 0\n",
    "                while iter < max_iters:\n",
    "                    print('################')\n",
    "                    print(f\"ITER: {iter}, parameters: {solution_master_pb[:self.K_MOD]}\")\n",
    "            \n",
    "                    ### Pricing problem\n",
    "                    lambda_k_iter = torch.tensor(solution_master_pb[:self.K_MOD], device= device , dtype=torch.float32)\n",
    "                    p_j_iter = torch.tensor(solution_master_pb[-self.num_objects:], device= device , dtype=torch.float32)\n",
    "                    B_star_si = []\n",
    "                    val_si = []\n",
    "                    for simul in range(self.num_simulations):\n",
    "                        B_star_i, val_i = self.linear_knapsack(\n",
    "                                                                    self.agents_i, \n",
    "                                                                    lambda_k_iter, \n",
    "                                                                    eps_i_j = self.eps_s_i_j[simul],\n",
    "                                                                    p_j = p_j_iter,\n",
    "                                                                    return_value = True\n",
    "                                                                    )\n",
    "            \n",
    "                        B_star_si.append(B_star_i)\n",
    "                        val_si.append(val_i)\n",
    "\n",
    "                    B_star_si = torch.cat(B_star_si, dim= 0)\n",
    "                    val_si = torch.cat(val_si, dim= 0)\n",
    "\n",
    "                    ### Stop if certificate holds\n",
    "                    certificate_i = val_si.cpu().numpy() - solution_master_pb[self.K_MOD: - self.num_objects]\n",
    "                    max_certificate = np.max(certificate_i)\n",
    "\n",
    "                    print(\"Value of LP:   \", model.objVal)\n",
    "                    print(f\"Reduced cost: {max_certificate}\")\n",
    "                    if max_certificate < tol:\n",
    "                            print('#############################################')\n",
    "                            print(\"Solution:       \", solution_master_pb[:self.K_MOD].round(3))\n",
    "                            if self.lambda_star_np is not None:\n",
    "                                print(\"True parameters:\", self.lambda_star_np)\n",
    "                            print('Number of iterations: ', iter)\n",
    "                            print('#############################################')\n",
    "                            return solution_master_pb , np.array(model.pi)\n",
    "\n",
    "                    ### Master problem\n",
    "                    # Add constraints\n",
    "                    B_star_si = B_star_si.cpu().numpy()\n",
    "                    φ_si_k_star = (self.φ_i_j_k_numpy[self.agents_si] * B_star_si[:,:,None]).sum(1)\n",
    "                    \n",
    "                    model.addConstrs(\n",
    "                                    (u_si[si] + gp.quicksum(p_j[j] for j in np.where(B_star_si[si])[0])\n",
    "                                    >= gp.quicksum((φ_si_k_star[si, k]) * lambda_k[k]  for k in range(self.K_MOD))\n",
    "                                    + self.eps_si_j[si, B_star_si[si]].sum()\n",
    "                                    for si in range(self.num_simulations * self.num_agents))\n",
    "                                    )\n",
    "                    \n",
    "                    # Solve master problem\n",
    "                    lambda_k.start = solution_master_pb[ : self.K_MOD]\n",
    "                    p_j.start = p_j_iter.cpu().numpy()\n",
    "                    u_si.start = val_si.cpu().numpy() \n",
    "\n",
    "                    model.optimize()\n",
    "                    solution_master_pb = np.array(model.x)\n",
    "\n",
    "                    iter += 1\n",
    "        \n",
    "\n",
    "BundledChoiceKP.estimate_GMM_matching_batched = estimate_GMM_matching_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
